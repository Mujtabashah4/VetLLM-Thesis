# ğŸš€ START HERE - VetLLM Fine-Tuning

**Complete production-ready pipeline for fine-tuning Alpaca-7B on veterinary data**

---

## âš¡ Quick Start (3 Steps)

### 1ï¸âƒ£ Install Dependencies

```bash
chmod +x setup.sh
./setup.sh
```

This will:
- âœ… Check your system (Python, GPU)
- âœ… Install all required packages
- âœ… Validate your data files
- âœ… Verify everything is ready

### 2ï¸âƒ£ Start Training

```bash
chmod +x start_training.sh
./start_training.sh
```

This will:
- âœ… Load your validated data
- âœ… Fine-tune Alpaca-7B with LoRA
- âœ… Save the trained model
- âœ… Show training progress

### 3ï¸âƒ£ Run Inference

```bash
python scripts/inference.py \
    --model models/vetllm-finetuned \
    --base-model-name wxjiao/alpaca-7b \
    --note "Cow. Clinical presentation includes epistaxis and high fever."
```

---

## ğŸ“‹ What's Configured

### âœ… Optimal Settings (Based on Working Notebook)

- **Model:** Alpaca-7B (wxjiao/alpaca-7b)
- **Method:** LoRA fine-tuning (memory efficient)
- **Precision:** FP16 mixed precision (full precision, no quantization)
- **Batch Size:** 4 per device
- **Effective Batch:** 16 (with gradient accumulation)
- **Learning Rate:** 2e-4 (optimized for LoRA)
- **Epochs:** 3 (configurable)
- **LoRA Rank:** 16, Alpha: 32

### âœ… Data Ready

All your data files are validated:
- `all_processed_data.json` - 1,602 samples âœ…
- `Cow_Buffalo_processed.json` - 746 samples âœ…
- `Sheep_Goat_processed.json` - 856 samples âœ…

**Total: 3,204 validated samples ready for training**

---

## ğŸ’» System Requirements

### Minimum
- NVIDIA GPU with 16GB+ VRAM
- 32GB system RAM
- 50GB free disk space
- Python 3.10+

### Recommended
- NVIDIA GPU with 24GB+ VRAM (A100, V100, RTX 3090/4090)
- CUDA 11.8 or 12.1+
- SSD for faster I/O

---

## ğŸ¯ Training Time Estimates

| GPU | Time per Epoch | Total (3 epochs) |
|-----|----------------|------------------|
| A100 (40GB) | ~30-45 min | ~2-3 hours |
| V100 (32GB) | ~45-60 min | ~3-4 hours |
| RTX 3090 (24GB) | ~60-90 min | ~4-6 hours |
| RTX 4090 (24GB) | ~45-60 min | ~3-4 hours |

---

## ğŸ“– Detailed Guides

- **Full Deployment Guide:** `DEPLOYMENT_GUIDE.md`
- **Quick Reference:** `README_DEPLOYMENT.md`
- **Implementation Details:** `PIPELINE_IMPLEMENTATION_REPORT.md`

---

## ğŸ”§ Customization

### Use Different Data File

```bash
./start_training.sh processed_data/Verified_DLO_data_-_\(Cow_Buffalo\)_processed.json
```

### Train for More Epochs

```bash
./start_training.sh processed_data/all_processed_data.json models/vetllm-finetuned 5
```

### Manual Training with Custom Settings

```bash
python scripts/train_vetllm.py \
    --data-path processed_data/all_processed_data.json \
    --output-dir models/vetllm-finetuned \
    --epochs 5 \
    --batch-size 8 \
    --learning-rate 1e-4
```

---

## âœ… Pre-Flight Checklist

Before starting, ensure:

- [ ] GPU with 16GB+ VRAM available
- [ ] CUDA installed and working (`nvidia-smi` works)
- [ ] Python 3.10+ installed
- [ ] Dependencies installed (`./setup.sh` completed)
- [ ] Data files validated (check `processed_data/` directory)
- [ ] Sufficient disk space (50GB+)
- [ ] Output directory writable

---

## ğŸ“ What Happens During Training

1. **Data Loading:** Loads and validates your training data
2. **Model Loading:** Downloads Alpaca-7B base model (first time only)
3. **LoRA Setup:** Applies LoRA adapters (only ~0.4% of parameters trainable)
4. **Training:** Fine-tunes on your veterinary data
5. **Saving:** Saves LoRA adapters every 100 steps
6. **Completion:** Best model automatically loaded at the end

---

## ğŸ“Š Expected Output

After training completes, you'll have:

```
models/vetllm-finetuned/
â”œâ”€â”€ adapter_config.json          # LoRA configuration
â”œâ”€â”€ adapter_model.safetensors    # Trained LoRA weights (~20MB)
â”œâ”€â”€ checkpoint-*/                # Training checkpoints
â”œâ”€â”€ logs/                        # Training logs
â””â”€â”€ training_args.json           # Training configuration
```

**Note:** Only LoRA adapters are saved (~20MB). The base model must be available for inference.

---

## ğŸš¨ Troubleshooting

### Out of Memory?

```bash
# Reduce batch size
python scripts/train_vetllm.py --batch-size 2 ...
```

### Slow Training?

1. Check CUDA: `python3 -c "import torch; print(torch.cuda.is_available())"`
2. Monitor GPU: `watch -n 1 nvidia-smi`

### Need Help?

- Check `DEPLOYMENT_GUIDE.md` for detailed troubleshooting
- Review training logs in `models/vetllm-finetuned/logs/`
- Check `PIPELINE_IMPLEMENTATION_REPORT.md` for technical details

---

## ğŸ‰ You're Ready!

Everything is configured and ready. Just run:

```bash
./setup.sh      # Install dependencies
./start_training.sh  # Start training
```

**That's it!** Your model will be fine-tuned and ready for accurate veterinary diagnosis predictions. ğŸš€

---

**Last Updated:** December 2024  
**Status:** âœ… Production Ready  
**Pipeline Version:** 2.0

